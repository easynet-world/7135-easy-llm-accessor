# Easy LLM Accessor

A developer-friendly, configurable LLM client supporting multiple providers, chat, and vision capabilities.

## ğŸš€ Latest Update

**Version 1.0.16** - Complete Ollama Provider Features (100% Implementation)

- âœ… Health Monitoring & Availability
- âœ… Model Switching & Management  
- âœ… Model Information Retrieval
- âœ… Streaming Support
- âœ… Advanced Configuration Options

## âœ¨ Features

## ğŸŒŸ Supported Providers

| Provider | Best For | Key Features |
|----------|----------|--------------|
| **OpenAI** | General purpose, vision | GPT-4, GPT-4 Vision |
| **Anthropic** | Safety, research | Claude 3 Sonnet, Haiku, Opus |
| **Ollama** | Privacy, local | Local deployment, custom models |
| **Groq** | Speed, real-time | Ultra-fast inference |
| **Grok** | Current events | Real-time knowledge |

## âš™ï¸ Configuration

```bash
# .env file
LLM_PROVIDER=openai  # openai, anthropic, ollama, groq, grok
OPENAI_API_KEY=your_key
OPENAI_MODEL=gpt-4

# Switch providers anytime
client.switchProvider('groq');
client.switchProvider('ollama');
```

## ğŸ¯ Key Features

- **ğŸ”„ Multi-Provider**: 5 major LLM providers in one client
- **ğŸ’¬ Chat & Vision**: Text and image analysis
- **ğŸ“¡ Streaming**: Real-time responses
- **ğŸ”§ Hot Switching**: Change providers without restarting
- **âš™ï¸ Unified API**: Same interface for all providers

## ğŸ“š Examples

```bash
node examples/comprehensive-usage.js
```

## ğŸ§ª Testing

```bash
npm test
```

---

**One client, multiple providers, unlimited possibilities.** ğŸš€

**Made with â¤ï¸ for developers who want AI without complexity.**
